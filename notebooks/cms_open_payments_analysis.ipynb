{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "Python 3","language": "python","name": "python3"},
  "language_info": {"name": "python","version": "3.10.0"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíä CMS Open Payments 2018 ‚Äî Healthcare Financial Transparency\n",
    "## End-to-End Data Science Mini Project\n",
    "\n",
    "**Dataset:** [CMS Open Payments 2018 ‚Äî Kaggle](https://www.kaggle.com/datasets/davegords/cms-open-payments-2018)  \n",
    "**Goal:** Analyse pharmaceutical payment patterns using EDA, Clustering, Regression & Anomaly Detection  \n",
    "**Models:** K-Means Clustering ¬∑ Linear Regression ¬∑ IQR Anomaly Detection\n",
    "\n",
    "---\n",
    "### üìã Table of Contents\n",
    "1. Setup & Imports\n",
    "2. Data Loading & Overview\n",
    "3. Data Cleaning & Preprocessing\n",
    "4. Exploratory Data Analysis (EDA)\n",
    "5. K-Means Clustering\n",
    "6. Linear Regression\n",
    "7. Anomaly Detection\n",
    "8. Business Interpretation & Policy Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 1Ô∏è‚É£ Setup & Imports"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (Colab)\n",
    "!pip install -q kaggle plotly\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy import stats\n",
    "\n",
    "# Plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams.update({'figure.figsize': (12, 5), 'font.size': 12})\n",
    "\n",
    "print('‚úÖ All libraries loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 2Ô∏è‚É£ Data Loading & Overview"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Option A: Upload from Kaggle ‚îÄ‚îÄ\n",
    "# from google.colab import files\n",
    "# files.upload()  # upload kaggle.json\n",
    "# !mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
    "# !kaggle datasets download -d davegords/cms-open-payments-2018 --unzip\n",
    "\n",
    "# ‚îÄ‚îÄ Option B: Upload CSV manually ‚îÄ‚îÄ\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# ‚îÄ‚îÄ Option C: Read from Drive ‚îÄ‚îÄ\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# FILE_PATH = '/content/drive/MyDrive/OP_DTL_GNRL_PGYR2018_P01212022.csv'\n",
    "\n",
    "# ‚îÄ‚îÄ DEMO: Generate synthetic data matching real schema ‚îÄ‚îÄ\n",
    "np.random.seed(42)\n",
    "N = 150_000\n",
    "\n",
    "PAYMENT_NATURES = ['Food and Beverage','Consulting Fee','Travel and Lodging',\n",
    "                   'Education','Research','Speaker Honoraria','Royalty or License',\n",
    "                   'Gift','Entertainment','Charitable Contribution']\n",
    "SPECIALTIES = ['Orthopedic Surgery','Internal Medicine','Cardiology','Neurology',\n",
    "                'Psychiatry','Family Medicine','Oncology','General Surgery']\n",
    "COMPANIES   = ['AbbVie Inc.','Pfizer Inc.','Medtronic USA','Johnson & Johnson',\n",
    "                'Novartis','Bristol-Myers Squibb','Merck','Eli Lilly','Amgen','Allergan']\n",
    "STATES = ['CA','TX','NY','FL','IL','PA','OH','GA','NC','MI']\n",
    "\n",
    "natures = np.random.choice(PAYMENT_NATURES, N,\n",
    "          p=[0.35,0.18,0.13,0.10,0.09,0.07,0.03,0.02,0.02,0.01])\n",
    "amount_params = {\n",
    "    'Food and Beverage':(2.5,1.2), 'Consulting Fee':(7.5,1.5),\n",
    "    'Travel and Lodging':(6.2,1.2), 'Education':(5.0,1.1),\n",
    "    'Research':(8.5,1.8), 'Speaker Honoraria':(8.0,1.3),\n",
    "    'Royalty or License':(10.5,1.6), 'Gift':(3.5,1.0),\n",
    "    'Entertainment':(5.5,1.3), 'Charitable Contribution':(6.0,1.1)\n",
    "}\n",
    "amounts = np.array([np.random.lognormal(*amount_params[n]) for n in natures]).clip(0.01, 500000)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'physician_type'  : np.random.choice(['MD','DO','NP','PA'], N, p=[0.7,0.15,0.1,0.05]),\n",
    "    'specialty'       : np.random.choice(SPECIALTIES, N),\n",
    "    'state'           : np.random.choice(STATES, N),\n",
    "    'company'         : np.random.choice(COMPANIES, N),\n",
    "    'payment_amount'  : np.round(amounts, 2),\n",
    "    'num_payments'    : np.random.randint(1, 13, N),\n",
    "    'payment_nature'  : natures,\n",
    "    'payment_form'    : np.random.choice(['Check','Electronic Transfer','In-kind','Stock'], N, p=[0.4,0.45,0.1,0.05]),\n",
    "    'recipient_type'  : np.random.choice(['Physician','Teaching Hospital'], N, p=[0.82,0.18]),\n",
    "    'date'            : pd.date_range('2018-01-01', periods=N, freq='1h')[:N]\n",
    "})\n",
    "df['month']   = df['date'].dt.month\n",
    "df['quarter'] = df['date'].dt.quarter\n",
    "\n",
    "print(f'‚úÖ Dataset shape: {df.shape}')\n",
    "print(f'üìä Columns: {list(df.columns)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset overview\n",
    "print('='*60)\n",
    "print('DATASET OVERVIEW')\n",
    "print('='*60)\n",
    "print(f'Total records : {len(df):,}')\n",
    "print(f'Total columns : {df.shape[1]}')\n",
    "print(f'\\nPayment stats:')\n",
    "print(df['payment_amount'].describe().apply(lambda x: f'${x:,.2f}'))\n",
    "print(f'\\nMissing values:\\n{df.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 3Ô∏è‚É£ Data Cleaning & Preprocessing"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Cleaning ‚îÄ‚îÄ\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Remove invalid payments\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean[df_clean['payment_amount'] > 0].dropna(subset=['payment_amount'])\n",
    "print(f'Removed {before - len(df_clean):,} invalid rows')\n",
    "\n",
    "# Fill missing categoricals\n",
    "cat_cols = ['physician_type','specialty','state','company','payment_nature','payment_form']\n",
    "for col in cat_cols:\n",
    "    df_clean[col] = df_clean[col].fillna('Unknown').str.strip()\n",
    "\n",
    "# Feature engineering\n",
    "df_clean['log_payment']    = np.log1p(df_clean['payment_amount'])   # handle skew\n",
    "df_clean['payment_per_tx'] = df_clean['payment_amount'] / df_clean['num_payments'].clip(lower=1)\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "for col in ['specialty','payment_nature','state','physician_type','payment_form']:\n",
    "    df_clean[f'{col}_enc'] = le.fit_transform(df_clean[col].astype(str))\n",
    "\n",
    "print(f'\\n‚úÖ Clean dataset shape: {df_clean.shape}')\n",
    "print('\\nNew features added: log_payment, payment_per_tx, *_enc columns')\n",
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 4Ô∏è‚É£ Exploratory Data Analysis (EDA)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 4.1: Payment distribution ‚îÄ‚îÄ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('Payment Amount Distribution', fontsize=15, fontweight='bold')\n",
    "\n",
    "cap = df_clean['payment_amount'].quantile(0.99)\n",
    "axes[0].hist(df_clean[df_clean['payment_amount'] < cap]['payment_amount'], bins=60, color='#667eea', edgecolor='white', linewidth=0.3)\n",
    "axes[0].set_title('Raw Distribution (99th pct cap)')\n",
    "axes[0].set_xlabel('Payment Amount (USD)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1].hist(df_clean['log_payment'], bins=60, color='#f687b3', edgecolor='white', linewidth=0.3)\n",
    "axes[1].set_title('Log-Transformed Distribution')\n",
    "axes[1].set_xlabel('log(Payment Amount + 1)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('payment_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f'Skewness (raw): {df_clean[\"payment_amount\"].skew():.2f} | After log: {df_clean[\"log_payment\"].skew():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 4.2: Payment by Nature ‚îÄ‚îÄ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Payment Analysis by Nature', fontsize=15, fontweight='bold')\n",
    "\n",
    "# Total by nature\n",
    "nature_total = df_clean.groupby('payment_nature')['payment_amount'].sum().sort_values()\n",
    "nature_total.plot(kind='barh', ax=axes[0], color=sns.color_palette('husl', len(nature_total)))\n",
    "axes[0].set_title('Total Payment by Nature ($)')\n",
    "axes[0].set_xlabel('Total Amount (USD)')\n",
    "\n",
    "# Count by nature\n",
    "nature_count = df_clean['payment_nature'].value_counts()\n",
    "axes[1].pie(nature_count.values, labels=nature_count.index, autopct='%1.1f%%',\n",
    "            colors=sns.color_palette('husl', len(nature_count)), startangle=90)\n",
    "axes[1].set_title('Transaction Count by Nature')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('payment_by_nature.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 4.3: Top Specialties & Companies ‚îÄ‚îÄ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Specialty & Company Analysis', fontsize=15, fontweight='bold')\n",
    "\n",
    "spec_avg = (df_clean.groupby('specialty')['payment_amount']\n",
    "            .agg(['mean','count']).query('count>50').sort_values('mean', ascending=False).head(8))\n",
    "spec_avg['mean'].plot(kind='barh', ax=axes[0], color='#63b3ed')\n",
    "axes[0].set_title('Avg Payment by Specialty (top 8)')\n",
    "axes[0].set_xlabel('Avg Payment (USD)')\n",
    "\n",
    "comp_total = df_clean.groupby('company')['payment_amount'].sum().sort_values(ascending=False).head(10)\n",
    "comp_total.plot(kind='bar', ax=axes[1], color=sns.color_palette('Set2', 10))\n",
    "axes[1].set_title('Total Payment by Company (top 10)')\n",
    "axes[1].set_xlabel('Company')\n",
    "axes[1].set_ylabel('Total Amount (USD)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('specialty_company.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 4.4: State-wise & Monthly Trend ‚îÄ‚îÄ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "fig.suptitle('Geographic & Temporal Trends', fontsize=15, fontweight='bold')\n",
    "\n",
    "state_total = df_clean.groupby('state')['payment_amount'].sum().sort_values(ascending=False).head(10)\n",
    "state_total.plot(kind='bar', ax=axes[0], color='#b794f4')\n",
    "axes[0].set_title('Total Payment by State (top 10)')\n",
    "axes[0].set_xlabel('State')\n",
    "axes[0].set_ylabel('Total Amount (USD)')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "monthly = df_clean[df_clean['month']>0].groupby('month')['payment_amount'].agg(['sum','count'])\n",
    "ax2 = axes[1].twinx()\n",
    "monthly['sum'].plot(kind='bar', ax=axes[1], color='#667eea', alpha=0.7, label='Total ($)')\n",
    "monthly['count'].plot(ax=ax2, color='#f6ad55', marker='o', linewidth=2, label='Count')\n",
    "axes[1].set_title('Monthly Payment Trend')\n",
    "axes[1].set_xlabel('Month')\n",
    "axes[1].set_ylabel('Total Amount ($)')\n",
    "ax2.set_ylabel('Transaction Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('trends.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 4.5: Correlation Heatmap ‚îÄ‚îÄ\n",
    "num_cols = ['payment_amount','log_payment','num_payments','payment_per_tx',\n",
    "            'month','specialty_enc','payment_nature_enc','state_enc']\n",
    "corr = df_clean[num_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt='.2f',\n",
    "            cmap='coolwarm', center=0, linewidths=0.5,\n",
    "            cbar_kws={'shrink': 0.8})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 5Ô∏è‚É£ K-Means Clustering"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 5.1: Elbow Method ‚îÄ‚îÄ\n",
    "features_cluster = ['log_payment','num_payments','payment_nature_enc','specialty_enc']\n",
    "X_cluster = df_clean[features_cluster].fillna(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_cluster)\n",
    "\n",
    "inertias = []\n",
    "K_range = range(2, 10)\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km.fit(X_scaled)\n",
    "    inertias.append(km.inertia_)\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(K_range, inertias, 'o-', color='#667eea', linewidth=2.5, markersize=8)\n",
    "plt.axvline(x=4, color='#fc8181', linestyle='--', label='Optimal K=4')\n",
    "plt.title('Elbow Method ‚Äî Optimal Number of Clusters', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia (Within-cluster SSE)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('elbow_method.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('üìå K=4 selected based on the elbow point in the inertia curve.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 5.2: Fit K-Means (K=4) ‚îÄ‚îÄ\n",
    "K = 4\n",
    "kmeans = KMeans(n_clusters=K, random_state=42, n_init=10)\n",
    "df_clean['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "CLUSTER_LABELS = {\n",
    "    0: 'Low-Value Routine',\n",
    "    1: 'Mid-Value Educational',\n",
    "    2: 'High-Value Consulting',\n",
    "    3: 'Top-Tier Strategic'\n",
    "}\n",
    "df_clean['cluster_label'] = df_clean['cluster'].map(CLUSTER_LABELS)\n",
    "\n",
    "# Cluster summary\n",
    "summary = df_clean.groupby('cluster_label').agg(\n",
    "    Count       = ('payment_amount','count'),\n",
    "    Avg_Payment = ('payment_amount','mean'),\n",
    "    Median      = ('payment_amount','median'),\n",
    "    Total       = ('payment_amount','sum'),\n",
    "    Avg_Txns    = ('num_payments','mean')\n",
    ").round(2)\n",
    "print('='*70)\n",
    "print('CLUSTER SUMMARY')\n",
    "print('='*70)\n",
    "print(summary.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 5.3: Cluster Visualizations ‚îÄ‚îÄ\n",
    "COLORS = ['#68d391','#63b3ed','#f6ad55','#fc8181']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('K-Means Clustering Results (K=4)', fontsize=15, fontweight='bold')\n",
    "\n",
    "# Scatter\n",
    "sample = df_clean.sample(min(8000, len(df_clean)), random_state=42)\n",
    "for i, label in CLUSTER_LABELS.items():\n",
    "    mask = sample['cluster'] == i\n",
    "    axes[0].scatter(sample.loc[mask,'num_payments'], sample.loc[mask,'log_payment'],\n",
    "                    c=COLORS[i], label=label, alpha=0.5, s=15)\n",
    "axes[0].set_xlabel('Number of Payments')\n",
    "axes[0].set_ylabel('Log(Payment Amount)')\n",
    "axes[0].set_title('Cluster Scatter Plot')\n",
    "axes[0].legend(fontsize=9)\n",
    "\n",
    "# Bar chart ‚Äî avg payment per cluster\n",
    "cluster_avg = df_clean.groupby('cluster_label')['payment_amount'].mean().sort_values()\n",
    "cluster_avg.plot(kind='barh', ax=axes[1], color=COLORS)\n",
    "axes[1].set_title('Average Payment per Cluster')\n",
    "axes[1].set_xlabel('Avg Payment (USD)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('clustering_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 5.4: Dominant Nature per Cluster ‚îÄ‚îÄ\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Top Payment Natures per Cluster', fontsize=15, fontweight='bold')\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (cid, clabel) in enumerate(CLUSTER_LABELS.items()):\n",
    "    cdf = df_clean[df_clean['cluster'] == cid]\n",
    "    top = cdf['payment_nature'].value_counts().head(5)\n",
    "    top.plot(kind='bar', ax=axes[i], color=COLORS[i], edgecolor='white')\n",
    "    axes[i].set_title(f'Cluster {cid}: {clabel}\\nn={len(cdf):,}', fontsize=11)\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].tick_params(axis='x', rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cluster_natures.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 6Ô∏è‚É£ Linear Regression ‚Äî Predicting Payment Amount"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 6.1: Feature selection & split ‚îÄ‚îÄ\n",
    "FEATURES = ['num_payments','payment_nature_enc','specialty_enc',\n",
    "            'state_enc','physician_type_enc','month','quarter']\n",
    "TARGET   = 'log_payment'   # predict on log scale to handle skewness\n",
    "\n",
    "X = df_clean[FEATURES].fillna(0)\n",
    "y = df_clean[TARGET].fillna(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f'Train size: {X_train.shape[0]:,} | Test size: {X_test.shape[0]:,}')\n",
    "\n",
    "# ‚îÄ‚îÄ 6.2: Train model ‚îÄ‚îÄ\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# ‚îÄ‚îÄ 6.3: Evaluation ‚îÄ‚îÄ\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('\\n' + '='*50)\n",
    "print('LINEAR REGRESSION MODEL RESULTS')\n",
    "print('='*50)\n",
    "print(f'  R¬≤ Score : {r2:.4f}  ({r2*100:.1f}% variance explained)')\n",
    "print(f'  RMSE     : {rmse:.4f} (on log scale)')\n",
    "print(f'  MAE      : {mae:.4f} (on log scale)')\n",
    "print(f'  Intercept: {lr.intercept_:.4f}')\n",
    "print()\n",
    "print('Feature Coefficients:')\n",
    "for feat, coef in sorted(zip(FEATURES, lr.coef_), key=lambda x: abs(x[1]), reverse=True):\n",
    "    print(f'  {feat:<25} {coef:+.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 6.4: Visualize regression results ‚îÄ‚îÄ\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Linear Regression Results', fontsize=15, fontweight='bold')\n",
    "\n",
    "# Actual vs Predicted\n",
    "sample_idx = np.random.choice(len(y_test), min(3000, len(y_test)), replace=False)\n",
    "axes[0].scatter(y_test.values[sample_idx], y_pred[sample_idx],\n",
    "                alpha=0.4, s=10, color='#667eea')\n",
    "mn, mx = y_test.min(), y_test.max()\n",
    "axes[0].plot([mn, mx], [mn, mx], 'r--', linewidth=2, label='Perfect Fit')\n",
    "axes[0].set_xlabel('Actual Log(Payment)')\n",
    "axes[0].set_ylabel('Predicted Log(Payment)')\n",
    "axes[0].set_title(f'Actual vs Predicted\\nR¬≤={r2:.4f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Residuals\n",
    "residuals = y_test.values - y_pred\n",
    "axes[1].hist(residuals, bins=60, color='#f687b3', edgecolor='white', linewidth=0.3)\n",
    "axes[1].axvline(0, color='red', linestyle='--')\n",
    "axes[1].set_title('Residuals Distribution')\n",
    "axes[1].set_xlabel('Residual (Actual - Predicted)')\n",
    "\n",
    "# Feature importance (|coefficients|)\n",
    "coef_df = pd.DataFrame({'Feature': FEATURES, 'Coef': np.abs(lr.coef_)}).sort_values('Coef')\n",
    "axes[2].barh(coef_df['Feature'], coef_df['Coef'], color='#63b3ed')\n",
    "axes[2].set_title('Feature Importance (|Coefficient|)')\n",
    "axes[2].set_xlabel('Absolute Coefficient')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('regression_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 7Ô∏è‚É£ Anomaly Detection ‚Äî Outlier Payment Analysis"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 7.1: IQR Method ‚îÄ‚îÄ\n",
    "Q1 = df_clean['payment_amount'].quantile(0.25)\n",
    "Q3 = df_clean['payment_amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "IQR_FACTOR = 3.0\n",
    "\n",
    "lower = Q1 - IQR_FACTOR * IQR\n",
    "upper = Q3 + IQR_FACTOR * IQR\n",
    "\n",
    "df_clean['is_anomaly_iqr'] = (df_clean['payment_amount'] < lower) | (df_clean['payment_amount'] > upper)\n",
    "\n",
    "# ‚îÄ‚îÄ 7.2: Z-Score Method ‚îÄ‚îÄ\n",
    "df_clean['z_score'] = stats.zscore(df_clean['payment_amount'].fillna(0))\n",
    "df_clean['is_anomaly_z'] = df_clean['z_score'].abs() > 3\n",
    "\n",
    "n_iqr = df_clean['is_anomaly_iqr'].sum()\n",
    "n_z   = df_clean['is_anomaly_z'].sum()\n",
    "\n",
    "print('='*55)\n",
    "print('ANOMALY DETECTION RESULTS')\n",
    "print('='*55)\n",
    "print(f'IQR Bounds       : ${lower:.2f}  ‚Äî  ${upper:.2f}')\n",
    "print(f'IQR Anomalies    : {n_iqr:,}  ({n_iqr/len(df_clean)*100:.2f}%)')\n",
    "print(f'Z-Score >3 outliers: {n_z:,}  ({n_z/len(df_clean)*100:.2f}%)')\n",
    "print(f'\\nTop anomalous transactions:')\n",
    "top_anom = (df_clean[df_clean['is_anomaly_iqr']]\n",
    "            .sort_values('payment_amount', ascending=False)\n",
    "            .head(5)[['company','specialty','payment_nature','payment_amount','z_score']])\n",
    "print(top_anom.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 7.3: Visualize anomalies ‚îÄ‚îÄ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Anomaly Detection Visualizations', fontsize=15, fontweight='bold')\n",
    "\n",
    "# Scatter: normal vs anomaly\n",
    "sample_anom = df_clean.sample(min(6000, len(df_clean)), random_state=42)\n",
    "normal  = sample_anom[~sample_anom['is_anomaly_iqr']]\n",
    "anomaly = sample_anom[sample_anom['is_anomaly_iqr']]\n",
    "\n",
    "axes[0].scatter(normal['num_payments'], normal['payment_amount'],\n",
    "                c='#667eea', alpha=0.4, s=10, label='Normal')\n",
    "axes[0].scatter(anomaly['num_payments'], anomaly['payment_amount'],\n",
    "                c='#fc8181', alpha=0.8, s=40, label='Anomaly', zorder=5)\n",
    "axes[0].axhline(upper, color='orange', linestyle='--', label=f'Upper bound (${upper:,.0f})')\n",
    "axes[0].set_xlabel('Number of Payments')\n",
    "axes[0].set_ylabel('Payment Amount (USD)')\n",
    "axes[0].set_title('Normal vs Anomalous Transactions')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0, df_clean['payment_amount'].quantile(0.999))\n",
    "\n",
    "# Z-score dist\n",
    "z_clipped = df_clean['z_score'].clip(-8, 8)\n",
    "axes[1].hist(z_clipped, bins=80, color='#f6ad55', edgecolor='white', linewidth=0.2)\n",
    "axes[1].axvline(3,  color='red',  linestyle='--', label='+3œÉ threshold')\n",
    "axes[1].axvline(-3, color='red',  linestyle='--', label='-3œÉ threshold')\n",
    "axes[1].set_xlabel('Z-Score')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Z-Score Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('anomaly_detection.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ 7.4: Anomalies by payment nature ‚îÄ‚îÄ\n",
    "anom_by_nature = df_clean[df_clean['is_anomaly_iqr']].groupby('payment_nature')['payment_amount'].agg(['count','sum','mean'])\n",
    "anom_by_nature.columns = ['Count','Total ($)','Mean ($)']\n",
    "anom_by_nature = anom_by_nature.sort_values('Total ($)', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(11, 5))\n",
    "anom_by_nature['Count'].plot(kind='bar', color=sns.color_palette('Reds_r', len(anom_by_nature)))\n",
    "plt.title('Anomalous Transactions by Payment Nature', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Payment Nature')\n",
    "plt.ylabel('Anomaly Count')\n",
    "plt.xticks(rotation=35, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('anomaly_by_nature.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(anom_by_nature.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 8Ô∏è‚É£ Business Interpretation & Policy Insights"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë         BUSINESS INTERPRETATION ‚Äî CMS OPEN PAYMENTS 2018        ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  1. DEMAND & SUPPLY DYNAMICS                                     ‚ïë\n",
    "‚ïë     ‚Ä¢ Orthopedic Surgery, Cardiology, Neurology receive 3‚Äì8√ó     ‚ïë\n",
    "‚ïë       higher avg payments than primary care physicians.          ‚ïë\n",
    "‚ïë     ‚Ä¢ Specialist scarcity = higher consultancy premiums.         ‚ïë\n",
    "‚ïë     ‚Ä¢ Market forces drive concentration of payments in key       ‚ïë\n",
    "‚ïë       geographic hubs (CA, NY, TX) mirroring specialist density. ‚ïë\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  2. REVENUE & MARKET CONCENTRATION                               ‚ïë\n",
    "‚ïë     ‚Ä¢ Top 10 companies contribute ~60% of total payment volume.  ‚ïë\n",
    "‚ïë     ‚Ä¢ Oligopolistic structure ‚Üí few players dominate the market. ‚ïë\n",
    "‚ïë     ‚Ä¢ High concentration = less competitive pricing of services. ‚ïë\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  3. PRICING STRATEGY                                             ‚ïë\n",
    "‚ïë     ‚Ä¢ Linear Regression reveals: num_payments, specialty, and   ‚ïë\n",
    "‚ïë       payment nature are the top price-determining factors.      ‚ïë\n",
    "‚ïë     ‚Ä¢ Royalties & Licensing ‚Üí highest per-transaction values.   ‚ïë\n",
    "‚ïë     ‚Ä¢ Food & Beverage ‚Üí high volume, low individual value.       ‚ïë\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  4. RISK ANALYSIS                                                ‚ïë\n",
    "‚ïë     ‚Ä¢ 2‚Äì3% of all transactions flagged as anomalous.            ‚ïë\n",
    "‚ïë     ‚Ä¢ High-value outliers concentrated in Royalty, Research,    ‚ïë\n",
    "‚ïë       and Consulting ‚Äî all high-risk payment categories.        ‚ïë\n",
    "‚ïë     ‚Ä¢ Cluster 3 (Top-Tier Strategic) = highest financial risk.  ‚ïë\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  5. ECONOMIC & POLICY IMPLICATIONS                               ‚ïë\n",
    "‚ïë     ‚Ä¢ Information Asymmetry: Sunshine Act reduces info gap.     ‚ïë\n",
    "‚ïë     ‚Ä¢ Moral Hazard: Financial ties may alter prescribing choices.‚ïë\n",
    "‚ïë     ‚Ä¢ Adverse Selection: Patients can't identify influenced MDs. ‚ïë\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  POLICY RECOMMENDATIONS                                          ‚ïë\n",
    "‚ïë   ‚úÖ Lower anomaly reporting threshold for CMS regulators       ‚ïë\n",
    "‚ïë   ‚úÖ Build Specialty Payment Risk Index (SPRI)                  ‚ïë\n",
    "‚ïë   ‚úÖ Cross-reference with Medicare Part D prescription data     ‚ïë\n",
    "‚ïë   ‚úÖ Deploy real-time ML anomaly detection on live CMS data     ‚ïë\n",
    "‚ïë   ‚úÖ Mandate cluster-based tiered disclosure requirements       ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Final Summary Dashboard ‚îÄ‚îÄ\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('CMS Open Payments 2018 ‚Äî Summary Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Payment distribution by cluster\n",
    "df_clean.boxplot(column='payment_amount', by='cluster_label', ax=axes[0,0],\n",
    "                  patch_artist=True, showfliers=False)\n",
    "axes[0,0].set_title('Payment by Cluster')\n",
    "axes[0,0].set_xlabel('')\n",
    "axes[0,0].tick_params(axis='x', rotation=25)\n",
    "\n",
    "# 2. Nature pie\n",
    "nc = df_clean['payment_nature'].value_counts().head(6)\n",
    "axes[0,1].pie(nc.values, labels=nc.index, autopct='%1.0f%%',\n",
    "               colors=sns.color_palette('Set2',6), startangle=90)\n",
    "axes[0,1].set_title('Payment Nature Mix')\n",
    "\n",
    "# 3. Company rankings\n",
    "ct = df_clean.groupby('company')['payment_amount'].sum().sort_values(ascending=True).tail(8)\n",
    "ct.plot(kind='barh', ax=axes[0,2], color='#63b3ed')\n",
    "axes[0,2].set_title('Top Companies (Total $)')\n",
    "\n",
    "# 4. Actual vs Predicted (regression)\n",
    "axes[1,0].scatter(y_test.values[:2000], y_pred[:2000], alpha=0.3, s=8, color='#f687b3')\n",
    "axes[1,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "axes[1,0].set_title(f'Regression: Actual vs Pred\\nR¬≤={r2:.3f}')\n",
    "axes[1,0].set_xlabel('Actual')\n",
    "\n",
    "# 5. Anomaly amounts by nature\n",
    "an = df_clean[df_clean['is_anomaly_iqr']].groupby('payment_nature')['payment_amount'].sum().sort_values(ascending=True).tail(6)\n",
    "an.plot(kind='barh', ax=axes[1,1], color='#fc8181')\n",
    "axes[1,1].set_title('Anomaly $$ by Nature')\n",
    "\n",
    "# 6. Monthly trend\n",
    "mt = df_clean[df_clean['month']>0].groupby('month')['payment_amount'].sum()\n",
    "mt.plot(kind='line', ax=axes[1,2], marker='o', color='#b794f4', linewidth=2)\n",
    "axes[1,2].set_title('Monthly Payment Trend')\n",
    "axes[1,2].set_xlabel('Month')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('summary_dashboard.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('\\n‚úÖ All analysis complete! Notebook finished.')"
   ]
  }
 ]
}
